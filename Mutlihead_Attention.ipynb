{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SvxpyUxQmqP"
   },
   "source": [
    "## Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "gqzOybgA6tDz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "a2NI4FSG8JY2"
   },
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 4\n",
    "d_model = 6\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RII2sE0iuSh",
    "outputId": "adc44ac9-82c0-4fc1-f6ac-13da59a079e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "xojRX8Q5jTfY"
   },
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim , 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "tnwj8NFTkWHC"
   },
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HICI_ofJk66H",
    "outputId": "83151566-80b1-4718-cabb-137cdb3eaf09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 18])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "Q2B8dXUlkkEE",
    "outputId": "fa91dc19-80e5-4ac8-b47b-41a1b36db856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "1jJM7kC4jilO"
   },
   "outputs": [],
   "source": [
    "num_heads = 3\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 6])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEXecxu5i9NA",
    "outputId": "b629f4d6-ec64-4f5e-937f-4c3e372f6af1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 6])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAqTTEP9q59y",
    "outputId": "cef8f870-b4fb-44b9-aaba-e71e4fc2801a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 192])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJd52g7CrCqy",
    "outputId": "18f3ad8f-012d-4169-fa45-e6c8466d1795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 4, 64]),\n",
       " torch.Size([4, 8, 4, 64]),\n",
       " torch.Size([4, 8, 4, 64]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJrxi4wdTPYO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUcuHtRt8H4x"
   },
   "source": [
    "## Self Attention for multiple heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5OYtIzMQ7iI"
   },
   "source": [
    "For a single head:\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywffyzop0pF-",
    "outputId": "5420219e-e438-4b9d-e0df-273ba9c5915d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIuhWR8TTGeO",
    "outputId": "3af47f70-a8c0-43f8-edb5-f2dcae5d957b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NH2091\\AppData\\Local\\Temp\\ipykernel_11276\\3717780648.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkUrLeoE5Vb6",
    "outputId": "c20f9988-839a-406b-eebe-242f8da41047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2859, -1.5363],\n",
       "        [ 0.0175,  0.7000],\n",
       "        [ 1.9211, -0.3058]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(2, 3)\n",
    "torch.transpose(y, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMaODlo-5Ygz",
    "outputId": "bc61ffd0-9db4-4d4a-dc01-7ee9a3456a3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2859, -1.5363],\n",
       "        [ 0.0175,  0.7000],\n",
       "        [ 1.9211, -0.3058]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0PL2TSC4ZTc",
    "outputId": "403fdc2a-8523-4f50-c4a2-38fd3a7af462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2) == k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daYW7MtI49t8",
    "outputId": "42d4c383-096d-49e3-a605-3d68d0274385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 64, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6tN6jvA0qur",
    "outputId": "84f0b8f6-0b97-431a-a0df-7c70ec973d41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size() , float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1] # mask for input to a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ8nYfdm1vis",
    "outputId": "7dc6378f-c50b-41d0-bece-ac2ff837f579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7817e-01,        -inf,        -inf,        -inf],\n",
       "        [-2.0877e-01,  1.9034e-01,        -inf,        -inf],\n",
       "        [-4.4298e-01,  5.0880e-01,  2.5273e-01,        -inf],\n",
       "        [-5.5707e-04, -7.6264e-01, -2.1010e-01,  1.2867e-01]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "efXdwo2U3FyI"
   },
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTazQyVQ3tz1",
    "outputId": "9c9c4ccc-e589-445a-810c-fef9c1339071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269606805367254"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.5596) / (np.exp(0.5596) + np.exp(0.0404))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "w9aR2BNP3Gw_"
   },
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kKHJqT83JSy",
    "outputId": "9cefdac2-080d-444c-8050-8643c2c0163c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SImzTnAl3L21",
    "outputId": "368b64c2-d53b-4dba-de02-d6a363e9d9af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4015, 0.5985, 0.0000, 0.0000],\n",
       "        [0.1787, 0.4629, 0.3584, 0.0000],\n",
       "        [0.2928, 0.1366, 0.2374, 0.3332]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNB5BsNyRYZP",
    "outputId": "4eeb673c-3f44-4f74-c2da-53a0321980b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 64])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAp7B9gDRgvW"
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "-C0rAup-rWNo"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Plrxn94Irs2K"
   },
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4agepAfr8_u",
    "outputId": "30ad86c7-bfd4-4d61-d645-5a1c00d48779"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 4])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ts-vwtNXrjFP",
    "outputId": "b493b5fc-b715-48fb-80d7-61b1a4dd2599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4015, 0.5985, 0.0000, 0.0000],\n",
       "        [0.1787, 0.4629, 0.3584, 0.0000],\n",
       "        [0.2928, 0.1366, 0.2374, 0.3332]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzMrh7Q8sKW5",
    "outputId": "a43e6c78-c9bd-47e2-eafe-1b91e4453362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4, 64])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqkGc4zdsOQ3",
    "outputId": "6dd47f8d-6a6c-4473-d810-9441155bd65b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 512])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "b7DH6VKMtMTu"
   },
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "n6zt1i51thgO"
   },
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38nDP4hGtjol",
    "outputId": "e1f02961-d7d2-4c2b-d496-9325258cdbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 512])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2NIAo2X6gIZ",
    "outputId": "6636d212-208d-4138-be57-81965c3a2d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1460, -0.4437,  0.3299,  ..., -0.1027,  0.2071,  0.4048],\n",
       "         [-0.4781, -0.1908, -0.2199,  ...,  0.1160, -0.0903,  0.2033],\n",
       "         [-0.0061, -0.0629, -0.0979,  ...,  0.2954, -0.2578, -0.2498],\n",
       "         [-0.3343,  0.3235,  0.2467,  ...,  0.2319,  0.0143, -0.1241]],\n",
       "\n",
       "        [[ 0.3411, -0.0219, -0.3118,  ...,  0.3943,  0.2416, -0.1059],\n",
       "         [-0.1558, -0.1289,  0.3654,  ...,  0.0781, -0.1360, -0.0658],\n",
       "         [-0.3007,  0.0847, -0.2209,  ..., -0.1745, -0.1231,  0.2222],\n",
       "         [ 0.0548,  0.2282,  0.0033,  ..., -0.1183, -0.1838,  0.3323]],\n",
       "\n",
       "        [[ 0.5242,  0.2897, -0.2201,  ..., -0.0619, -0.1812, -0.4211],\n",
       "         [ 0.3865, -0.5457, -0.0801,  ..., -0.1175, -0.0403,  0.1935],\n",
       "         [ 0.1393, -0.1597,  0.4671,  ..., -0.0283,  0.2709,  0.0390],\n",
       "         [ 0.3024,  0.3523, -0.0506,  ..., -0.3048,  0.1508,  0.6844]],\n",
       "\n",
       "        [[-0.0878,  0.0008, -0.7466,  ...,  0.0776, -0.0013,  0.1287],\n",
       "         [-0.0571,  0.2748,  0.1312,  ...,  0.1070,  0.0786,  0.4032],\n",
       "         [-0.0614, -0.0243, -0.5223,  ..., -0.2304, -0.2338, -0.1981],\n",
       "         [ 0.2834,  0.0304,  0.2966,  ..., -0.2851,  0.3218,  0.2761]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmRfc7fhtc1U"
   },
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "NSIKbDEXtcOv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ux6hMEjyWEU"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiB-SkfaxCTl",
    "outputId": "04f0a850-3a4d-427d-9345-f17082789c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "84AaNS24xuUV"
   },
   "outputs": [],
   "source": [
    "embedding_dim=12\n",
    "attention_dim=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=nn.Linear(embedding_dim,attention_dim, bias=False)\n",
    "key=nn.Linear(embedding_dim,attention_dim,bias=False)\n",
    "value=nn.Linear(embedding_dim,attention_dim,bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=1\n",
    "s=4\n",
    "i=12\n",
    "embedded=torch.randn((b,s,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=query(embedded)\n",
    "k=key(embedded)\n",
    "v=value(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_len,context_len=q.shape[-1],q.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=torch.matmul(q,k.transpose(-2,-1))/attn_len**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2294,  1.8679, -0.4667,  2.2280,  0.1020, -0.7011,  0.0622,\n",
       "           0.3732,  1.0044,  0.1114, -0.5365,  1.5790],\n",
       "         [-1.1151,  2.7913, -0.0406,  1.4016, -0.3440, -1.5138,  1.1701,\n",
       "          -2.8675, -0.8803,  0.9443,  0.7478, -0.2396],\n",
       "         [-0.6904,  0.3364, -1.8404,  1.0603,  0.0513, -0.0158,  0.4949,\n",
       "          -0.5014, -0.8195, -0.6751, -0.2116,  0.3811],\n",
       "         [-0.2394,  0.2485,  0.0509,  0.2072,  0.7934, -1.1592, -1.1003,\n",
       "           0.2354, -0.2723, -1.3261, -1.2496,  0.9633]]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_triangular = torch.tril(torch.ones(context_len, context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_triangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.ones(context_len, context_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = lower_triangular == 0\n",
    "scores = scores.masked_fill(mask, float('-inf'))\n",
    "scores = nn.functional.softmax(scores, dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4975, 0.5025, 0.0000, 0.0000],\n",
       "         [0.3136, 0.3638, 0.3226, 0.0000],\n",
       "         [0.2576, 0.2294, 0.2477, 0.2654]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embed=torch.matmul(scores,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embed=torch.round(new_embed,decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2033,  0.2665, -0.2036],\n",
       "         [ 0.1566,  0.3518,  0.7729],\n",
       "         [ 0.0982,  0.1880,  0.8601],\n",
       "         [-0.0037,  0.1493,  0.5442]]], grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttn(nn.Module):\n",
    "    \n",
    "    def __init__(self,batch,seq_len,embed_dim,attn_dim,num_heads=1):\n",
    "        super().__init__()\n",
    "        self.batch=batch\n",
    "        self.seq_len=seq_len\n",
    "        self.embed_dim=embed_dim\n",
    "        self.attn_dim=attn_dim\n",
    "        self.num_heads=3\n",
    "        \n",
    "        \n",
    "        self.query=nn.Linear(embed_dim,attn_dim*num_heads)\n",
    "        \n",
    "        self.key=nn.Linear(embed_dim,attn_dim*num_heads)\n",
    "        \n",
    "        self.value=nn.Linear(embed_dim,attn_dim*num_heads)\n",
    "        \n",
    "        \n",
    "    def forward(self,embedded,add=False):\n",
    "        \n",
    "        print(embedded.shape)\n",
    "        \n",
    "        q=self.query(embedded).view(self.batch,self.seq_len,self.num_heads,self.attn_dim).transpose(1,2)\n",
    "        k=self.key(embedded).view(self.batch,self.seq_len,self.num_heads,self.attn_dim).transpose(1,2)\n",
    "        v=self.value(embedded).view(self.batch,self.seq_len,self.num_heads,self.attn_dim).transpose(1,2)\n",
    "        \n",
    "        print(q.shape,k.shape,v.shape)\n",
    "        \n",
    "\n",
    "        scores=torch.matmul(q,k.transpose(-2,-1))/(self.attn_dim)**(0.5)\n",
    "                \n",
    "        lower_tr=torch.tril(torch.ones(self.seq_len,self.seq_len))\n",
    "        \n",
    "        print(scores.shape,lower_tr.shape)\n",
    "        \n",
    "        mask=lower_tr==0\n",
    "                \n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        \n",
    "        scores_scaled=nn.functional.softmax(scores,dim=-1)\n",
    "        \n",
    "        print(scores_scaled)\n",
    "\n",
    "        \n",
    "        ans=torch.round(torch.matmul(scores_scaled,v),decimals=4)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        attn_output = ans.transpose(1, 2).contiguous().view(self.batch, self.seq_len, -1)  # [batch_size, seq_len, num_heads * attn_dim]\n",
    "        \n",
    "        \n",
    "        if add:\n",
    "            ans=v+ans\n",
    "            \n",
    "        # Normalize the output\n",
    "        mean = torch.mean(attn_output, dim=-1, keepdim=True)\n",
    "        std = torch.std(attn_output, dim=-1, keepdim=True)\n",
    "        normalized_output = (attn_output - mean) / std\n",
    "\n",
    "        return normalized_output, scores_scaled    \n",
    "            \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=SelfAttn(2,5,12,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfAttn(\n",
       "  (query): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (key): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (value): Linear(in_features=12, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "s=5\n",
    "e_d=12\n",
    "X=torch.randn((b,s,e_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 12])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 12])\n",
      "torch.Size([2, 3, 5, 4]) torch.Size([2, 3, 5, 4]) torch.Size([2, 3, 5, 4])\n",
      "torch.Size([2, 3, 5, 5]) torch.Size([5, 5])\n",
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4185, 0.5815, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3843, 0.2562, 0.3596, 0.0000, 0.0000],\n",
      "          [0.2547, 0.2947, 0.2263, 0.2242, 0.0000],\n",
      "          [0.1800, 0.2383, 0.1709, 0.2516, 0.1592]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5123, 0.4877, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3015, 0.3739, 0.3247, 0.0000, 0.0000],\n",
      "          [0.4486, 0.2695, 0.1074, 0.1745, 0.0000],\n",
      "          [0.0890, 0.1591, 0.3737, 0.2220, 0.1563]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3769, 0.6231, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4126, 0.3807, 0.2067, 0.0000, 0.0000],\n",
      "          [0.2095, 0.1978, 0.3233, 0.2693, 0.0000],\n",
      "          [0.2141, 0.3499, 0.1431, 0.1841, 0.1088]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3154, 0.6846, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3265, 0.3136, 0.3599, 0.0000, 0.0000],\n",
      "          [0.2343, 0.1149, 0.2707, 0.3801, 0.0000],\n",
      "          [0.2217, 0.3581, 0.1372, 0.1403, 0.1427]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6186, 0.3814, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3203, 0.3715, 0.3083, 0.0000, 0.0000],\n",
      "          [0.2459, 0.2779, 0.2024, 0.2739, 0.0000],\n",
      "          [0.1546, 0.2621, 0.1495, 0.2413, 0.1924]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4589, 0.5411, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3207, 0.4217, 0.2576, 0.0000, 0.0000],\n",
      "          [0.1877, 0.3328, 0.1511, 0.3285, 0.0000],\n",
      "          [0.1877, 0.2285, 0.2068, 0.2286, 0.1484]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sc=a.forward(X,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6752,  0.4766,  0.4773, -0.4771, -1.7998, -0.2166,  1.2526,\n",
       "           1.1934, -1.6441,  0.1241,  0.6257, -0.6873],\n",
       "         [ 1.7380,  0.4347,  0.3487, -0.9242, -0.5140, -0.7274,  0.5186,\n",
       "          -0.0228, -0.6842,  1.0468,  0.7063, -1.9207],\n",
       "         [ 1.3987,  0.1305,  0.7149, -0.4620, -1.2054, -0.2931,  0.4280,\n",
       "           0.0830, -0.9554,  1.2193,  0.8149, -1.8734],\n",
       "         [ 1.3249,  0.5485,  0.6543, -0.1429, -1.4820, -0.4164,  1.4353,\n",
       "           0.7147, -0.9462,  0.3472, -0.5375, -1.5000],\n",
       "         [ 1.1955,  0.0403, -0.0410, -1.0374, -1.6700,  0.7623,  0.2293,\n",
       "           0.6755, -0.7272,  1.3561,  0.5927, -1.3760]],\n",
       "\n",
       "        [[ 0.6306, -0.9708,  0.1337, -1.9162,  0.1721,  0.6580, -0.5153,\n",
       "           0.0463,  0.5335, -0.0995, -0.7616,  2.0893],\n",
       "         [ 1.2208,  0.6294, -1.0444, -1.2848,  0.3988, -1.0714,  0.6707,\n",
       "           0.3236, -1.6195,  0.1302,  0.3157,  1.3308],\n",
       "         [ 0.7627, -0.3102, -1.4918, -1.5958,  0.7164, -0.4190,  0.8189,\n",
       "           0.4622, -1.2147,  0.5517,  0.2605,  1.4592],\n",
       "         [-0.2123, -1.1581, -0.4090, -1.3331,  0.2916, -0.1196,  1.2136,\n",
       "           1.6003, -1.2993, -0.4080,  0.9130,  0.9210],\n",
       "         [ 0.8135, -0.0936, -0.9390, -1.5660,  0.3318, -0.7115,  1.4283,\n",
       "           1.5590, -1.1973, -0.3692,  0.1965,  0.5475]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1590,  0.2226,  0.7693, -0.0558],\n",
      "         [-0.3940, -0.2064,  0.3827, -0.1066],\n",
      "         [-0.2045, -0.2629, -0.0982, -0.3237]],\n",
      "\n",
      "        [[-0.7310, -0.0329,  0.0635, -0.3970],\n",
      "         [-0.2958, -0.0576,  0.2643, -0.4464],\n",
      "         [ 0.1081, -0.0764,  0.3632, -0.5046]]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttn(nn.Module):\n",
    "    def __init__(self, batch, seq_len, embed_dim, attn_dim, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.batch = batch\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, attn_dim * num_heads)\n",
    "        self.key = nn.Linear(embed_dim, attn_dim * num_heads)\n",
    "        self.value = nn.Linear(embed_dim, attn_dim * num_heads)\n",
    "        \n",
    "        self.scale_factor = attn_dim ** 0.5\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        batch_size = embedded.size(0)\n",
    "\n",
    "        # Linear projections\n",
    "        q = self.query(embedded).view(batch_size, self.seq_len, self.num_heads, self.attn_dim)\n",
    "        k = self.key(embedded).view(batch_size, self.seq_len, self.num_heads, self.attn_dim)\n",
    "        v = self.value(embedded).view(batch_size, self.seq_len, self.num_heads, self.attn_dim)\n",
    "\n",
    "        # Transpose for attention calculation\n",
    "        q = q.transpose(1, 2)  # (batch_size, num_heads, seq_len, attn_dim)\n",
    "        k = k.transpose(1, 2)  # (batch_size, num_heads, seq_len, attn_dim)\n",
    "        v = v.transpose(1, 2)  # (batch_size, num_heads, seq_len, attn_dim)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale_factor\n",
    "        \n",
    "        # Masking to prevent attending to future tokens\n",
    "        lower_tr = torch.tril(torch.ones(self.seq_len, self.seq_len, device=scores.device))\n",
    "        mask = lower_tr == 0\n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        # Softmax to get attention probabilities\n",
    "        attn_probs = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Attention output\n",
    "        attn_output = torch.matmul(attn_probs, v)  # (batch_size, num_heads, seq_len, attn_dim)\n",
    "        \n",
    "        # Concatenate heads and round results\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, self.seq_len, -1)\n",
    "        \n",
    "        # Round to the specified number of decimals\n",
    "        decimals = 4\n",
    "        scaling_factor = 10 ** decimals\n",
    "        attn_output = torch.round(attn_output * scaling_factor) / scaling_factor\n",
    "        \n",
    "        return attn_output\n",
    "\n",
    "# Example usage\n",
    "batch = 2\n",
    "seq_len = 3\n",
    "embed_dim = 4\n",
    "attn_dim = 2\n",
    "num_heads = 2\n",
    "\n",
    "self_attn = SelfAttn(batch, seq_len, embed_dim, attn_dim, num_heads)\n",
    "embedded = torch.randn(batch, seq_len, embed_dim)\n",
    "output = self_attn(embedded)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchtyping import TensorType\n",
    "\n",
    "class Solution(nn.Module):\n",
    "    def __init__(self, vocabulary_size: int):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        self.embedding_layer=nn.Embedding(vocabulary_size,16)\n",
    "\n",
    "        self.linear_layer=nn.Linear(16,1)\n",
    "\n",
    "        self.sigmoid_layer=nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x) :\n",
    "        # Hint: The embedding layer outputs a B, T, embed_dim tensor\n",
    "        # but you should average it into a B, embed_dim tensor before using the Linear layer\n",
    "        embeddings=self.embedding_layer(x)\n",
    "        \n",
    "#         return embeddings\n",
    "        \n",
    "        averaged=torch.mean(embeddings, axis=2)\n",
    "        \n",
    "#         return averaged\n",
    "\n",
    "        projected=self.linear_layer(averaged)\n",
    "\n",
    "        return torch.round(self.sigmoid_layer(projected),decimals=2)\n",
    "        # Return a B, 1 tensor and round to 4 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Solution(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NH2091\\AppData\\Local\\Temp\\ipykernel_11276\\174707659.py:1: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor([[\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[\n",
    " [2.0, 7.0, 14.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "[1.0, 4.0, 12.0, 3.0, 10.0, 5.0, 15.0, 11.0, 6.0, 9.0, 13.0, 7.0]],\n",
    "    \n",
    "[[26.0, 7.0, 14.0, 8.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "[1.0, 4.0, 12.0, 3.0, 9.0, 5.0, 15.0, 11.0, 6.0, 9.0, 13.0, 7.0]]\n",
    "],\n",
    "    dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 12])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=s.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1])"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1])"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4800], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.4800]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4]\n",
    "b=[4,5,6,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array(a)\n",
    "b=np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "a%b\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    val=1/(1+np.exp(-x))\n",
    "    \n",
    "    return val\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7039646260537472"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8662491540539735"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 3])"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.dot>"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2096)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.randn(5),torch.randn(5))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
